import streamlit as st
from langchain_core.messages.chat import ChatMessage
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import PromptTemplate


# ì„ë² ë”© ëª¨ë¸ ì •ì˜
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¡œë“œ
vectorstore = FAISS.load_local(
    folder_path="faiss_db",
    index_name="k-ics",
    embeddings=embeddings,
    allow_dangerous_deserialization=True,
)

retriever = vectorstore.as_retriever()


# API KEY ì •ë³´ë¡œë“œ
load_dotenv()

st.title("K-ICS HelperğŸ“")

# ì²˜ìŒ 1ë²ˆë§Œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì½”ë“œ
if "messages" not in st.session_state:
    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ìƒì„±í•œë‹¤.
    st.session_state["messages"] = []

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # ëŒ€í™”ì´ˆê¸°í™” ë²„íŠ¼
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")


# ì´ì „ ëŒ€í™”ë¥¼ ì¶œë ¥
def print_messages():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)


# ìƒˆë¡œìš´ ë§¤ì„¸ì§€ë¥¼ ì¶”ê°€
def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


# ì²´ì¸ì„ ìƒì„±
# ì²´ì¸ì„ ìƒì„±
def create_chain():
    # prompt | llm | output_parser
    prompt = PromptTemplate.from_template(
    """You are an assistant for question-answering tasks. 
    Use the following pieces of retrieved context to answer the question. 
    If you don't know the answer, just say that you don't know. 
    you must include 'page' number and document name.
    Answer in Korean.

    #Context: 
    {context}

    #Question:
    {question}

    #Answer:"""
    )
 
    # GPT
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
    # ì¶œë ¥íŒŒì„œ
    output_parser = StrOutputParser()

    # ì²´ì¸ ìƒì„±
    chain = (
        {"context": lambda question: retriever.get_relevant_documents(str(question)),  # ì§ˆë¬¸ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
         "question": RunnablePassthrough()}
        | prompt
        | llm
        | output_parser
    )

    return chain

# ì´ˆê¸°í™” ë²„íŠ¼ì´ ëˆŒë¦¬ë©´?
if clear_btn:
    st.session_state["messages"] = []

# ì´ì „ ëŒ€í™”ê¸°ë¡ ìƒì„±
print_messages()

# ì‚¬ìš©ìì˜ ì…ë ¥
user_input = st.chat_input("K-ICS ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”")

# ë§Œì•½ì— ì‚¬ìš©ìì˜ ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´
if user_input:
    # ì‚¬ìš©ìì˜ ì…ë ¥
    st.chat_message("user").write(user_input)

    # chain ì„ ìƒì„±
    chain = create_chain()
    response = chain.stream({"question": user_input})
    with st.chat_message("assistant"):
        # ë¹ˆ ê³µê°„ì„ ë§Œë“¤ì–´ì„œ ì—¬ê¸°ì— í† í°ì„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥)
        container = st.empty()
        ai_answer = ""
        for token in response:
            ai_answer += token
            container.markdown(ai_answer)

    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤
    add_message("user", user_input)
    add_message("assistant", ai_answer)



# retriever í…ŒìŠ¤íŠ¸
test_query = "K-ICS ë¬¸ì„œì˜ ì¼ë¶€ ë‚´ìš© ì˜ˆì‹œ"  # í…ŒìŠ¤íŠ¸í•  ì§ˆë¬¸
docs = retriever.get_relevant_documents(test_query)

# ë°˜í™˜ëœ ë¬¸ì„œ ì¶œë ¥
if docs:
    for doc in docs:
        print(doc.page_content)  # ê° ë¬¸ì„œì˜ ë‚´ìš© ì¶œë ¥
else:
    print("ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
